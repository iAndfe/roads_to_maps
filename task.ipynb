{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and Analyzing Road Networks\n",
    "\n",
    "This notebook is for processing road data by matching road names between two CSVs using fuzzy matching, then creating a linestring road segment from GPS co-ordinates. This is useful for when you get scammed to provide an overengineered solution when you do not have access to the original corridors geospatial dataset.\n",
    "\n",
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "\n",
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining preprocessing and fuzzy matching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_road_name(road_name):\n",
    "    if not isinstance(road_name, str):\n",
    "        return None\n",
    "    first_word = road_name.split()[0].lower()\n",
    "    return first_word\n",
    "\n",
    "def fuzzy_match(row, choices, threshold):\n",
    "    if not isinstance(row, str):\n",
    "        return None\n",
    "    best_match, score = process.extractOne(row, choices)\n",
    "    if score > threshold:\n",
    "        return best_match\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the main function to process the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv(input_file):\n",
    "    linz = pd.read_csv('nz-roads-addressing.csv')\n",
    "    shu = pd.read_csv(input_file)\n",
    "\n",
    "    shu['Road Name'] = shu['Road Name'].astype(str)\n",
    "\n",
    "    shu['Processed Road Name'] = shu['Road Name'].apply(preprocess_road_name)\n",
    "    shu_roads_list = shu['Processed Road Name'].tolist()\n",
    "\n",
    "    linz['Processed_Full_Road_Name'] = linz['full_road_name'].apply(preprocess_road_name)\n",
    "    linz['Processed_Road_Name_Label'] = linz['road_name_label'].apply(preprocess_road_name)\n",
    "\n",
    "    threshold = 90\n",
    "    linz['Matched_Road_Full'] = linz['Processed_Full_Road_Name'].apply(lambda x: fuzzy_match(x, shu_roads_list, threshold))\n",
    "    linz['Matched_Road_Label'] = linz['Processed_Road_Name_Label'].apply(lambda x: fuzzy_match(x, shu_roads_list, threshold))\n",
    "\n",
    "    matched_roads = linz.dropna(subset=['Matched_Road_Full', 'Matched_Road_Label'], how='all')\n",
    "\n",
    "    result_full = matched_roads.merge(shu, left_on='Matched_Road_Full', right_on='Processed Road Name', how='inner')\n",
    "    result_label = matched_roads.merge(shu, left_on='Matched_Road_Label', right_on='Processed Road Name', how='inner')\n",
    "\n",
    "    result = pd.concat([result_full, result_label], ignore_index=True)\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute the main function and do the first part of data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = process_csv(\"shu_raw/local2.csv\")\n",
    "\n",
    "columns_to_keep = ['road_id', 'full_road_name', 'road_name_label', 'Road Name', 'Corridor ID', 'Land Use',\n",
    "                    'Traffic Volume', 'Street Category', 'Collective Risk Band', 'Personal Risk Band',\n",
    "                    'Posted Speed Limit', 'Free Flow Speed', 'IRR Band', 'Safe and Appropriate Speed',\n",
    "                    'Difference between posted speed limit and SaAS', 'Difference between operating and SaAS',\n",
    "                    'Proposed Permanent Speed Limit', 'Proposed Variable Speed Limit', 'Start GPS Co-ordinates',\n",
    "                    'End GPS Co-ordinates']\n",
    "result_df = result_df[columns_to_keep]\n",
    "\n",
    "result_df = result_df.drop_duplicates(subset=['Start GPS Co-ordinates'], keep='first')\n",
    "result_df = result_df.dropna(subset=['Start GPS Co-ordinates'])\n",
    "result_df = result_df.drop_duplicates(subset=['Start GPS Co-ordinates'], keep='first').dropna(subset=['Start GPS Co-ordinates'])\n",
    "\n",
    "result_df.to_csv(\"combined.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note now you have \"combined.csv\" this should be manually checked and edited, to confirm roads have joined correctly. Deleting duplicates manually is recommended before continuing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for geo-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_linestring(geom):\n",
    "    return geom.geom_type == 'LineString'\n",
    "\n",
    "def safe_convert(coord):\n",
    "    try:\n",
    "        coord_list = ast.literal_eval(coord)\n",
    "        return Point(float(coord_list[1]), float(coord_list[0]))\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan\n",
    "    \n",
    "def closest_point(point, linestring):\n",
    "    closest_point = linestring.interpolate(linestring.project(point))\n",
    "    return closest_point\n",
    "\n",
    "def cut_linestring_at_points(linestring, point1, point2):\n",
    "    fraction1 = linestring.project(point1)\n",
    "    fraction2 = linestring.project(point2)\n",
    "\n",
    "    # Make sure fraction1 is smaller than fraction2\n",
    "    if fraction1 > fraction2:\n",
    "        fraction1, fraction2 = fraction2, fraction1\n",
    "\n",
    "    # Get the coordinates between the two projected points\n",
    "    coords = [coord for coord in linestring.coords if fraction1 <= linestring.project(Point(coord)) <= fraction2]\n",
    "\n",
    "    # Include the projected points in the final segment\n",
    "    segment = LineString([linestring.interpolate(fraction1), *coords, linestring.interpolate(fraction2)])\n",
    "\n",
    "    return segment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Geoprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anfe\\AppData\\Local\\Temp\\ipykernel_21104\\899556860.py:30: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  merged_gdf.to_file(\"output/output.shp\")\n"
     ]
    }
   ],
   "source": [
    "# Assume that the dataset is already a singlepart Linestring\n",
    "road_network = gpd.read_file('explode-dissolve/roads.shp')\n",
    "road_network['road_id'] = road_network['road_id'].astype(str)\n",
    "\n",
    "df = pd.read_csv('combined.csv')\n",
    "\n",
    "df['StartPoint'] = df['Start GPS Co-ordinates'].apply(safe_convert)\n",
    "df['EndPoint'] = df['End GPS Co-ordinates'].apply(safe_convert)\n",
    "\n",
    "points_gdf = gpd.GeoDataFrame(df, geometry='StartPoint')\n",
    "\n",
    "points_gdf['road_id'] = points_gdf['road_id'].astype('int64')\n",
    "road_network['road_id'] = road_network['road_id'].astype('int64')\n",
    "\n",
    "road_network.rename(columns={'geometry': 'geometry_road'}, inplace=True)\n",
    "merged_gdf = points_gdf.merge(road_network, how='left', on='road_id')\n",
    "\n",
    "# Filter out rows where 'geometry_road' is a MultiLineString\n",
    "merged_gdf = merged_gdf[merged_gdf['geometry_road'].apply(is_linestring)]\n",
    "\n",
    "merged_gdf['Start_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['StartPoint'], row['geometry_road']), axis=1)\n",
    "merged_gdf['End_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['EndPoint'], row['geometry_road']), axis=1)\n",
    "\n",
    "merged_gdf['Road_Segment'] = merged_gdf.apply(lambda row: cut_linestring_at_points(row['geometry_road'], row['Start_Closest_Point'], row['End_Closest_Point']), axis=1)\n",
    "\n",
    "merged_gdf.drop(columns=['StartPoint', 'Start_Closest_Point', 'geometry_road', 'End_Closest_Point', 'EndPoint'], inplace=True)\n",
    "\n",
    "merged_gdf.set_geometry('Road_Segment', inplace=True)\n",
    "\n",
    "merged_gdf.to_file(\"output/output.shp\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
