{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and Analyzing Road Networks\n",
    "\n",
    "This notebook is for processing road data by matching road names between two CSVs using fuzzy matching, then creating a linestring road segment from GPS co-ordinates. This is useful for when you get scammed to provide an overengineered solution when you do not have access to the original corridors geospatial dataset.\n",
    "\n",
    "It is recommended to create a virtual environment in this directory (.venv)\n",
    "\n",
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining preprocessing and fuzzy matching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_road_name(road_name):\n",
    "    if not isinstance(road_name, str):\n",
    "        return None\n",
    "    first_word = road_name.split()[0].lower()\n",
    "    return first_word\n",
    "\n",
    "def fuzzy_match(row, choices, threshold):\n",
    "    if not isinstance(row, str):\n",
    "        return None\n",
    "    best_match, score = process.extractOne(row, choices)\n",
    "    if score > threshold:\n",
    "        return best_match\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to pre-process the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_corridors(input_file, output_file):\n",
    "    linz = pd.read_csv('nz-roads-addressing.csv')\n",
    "    shu = pd.read_csv(input_file)\n",
    "\n",
    "    shu['Road Name'] = shu['Road Name'].astype(str)\n",
    "    shu['Processed Road Name'] = shu['Road Name'].apply(preprocess_road_name)\n",
    "    shu_roads_list = shu['Processed Road Name'].tolist()\n",
    "\n",
    "    linz['Processed_Full_Road_Name'] = linz['full_road_name'].apply(preprocess_road_name)\n",
    "    linz['Processed_Road_Name_Label'] = linz['road_name_label'].apply(preprocess_road_name)\n",
    "\n",
    "    threshold = 90\n",
    "    linz['Matched_Road_Full'] = linz['Processed_Full_Road_Name'].apply(lambda x: fuzzy_match(x, shu_roads_list, threshold))\n",
    "    linz['Matched_Road_Label'] = linz['Processed_Road_Name_Label'].apply(lambda x: fuzzy_match(x, shu_roads_list, threshold))\n",
    "\n",
    "    matched_roads = linz.dropna(subset=['Matched_Road_Full', 'Matched_Road_Label'], how='all')\n",
    "\n",
    "    result_full = matched_roads.merge(shu, left_on='Matched_Road_Full', right_on='Processed Road Name', how='inner')\n",
    "    result_label = matched_roads.merge(shu, left_on='Matched_Road_Label', right_on='Processed Road Name', how='inner')\n",
    "\n",
    "    result = pd.concat([result_full, result_label], ignore_index=True)\n",
    "    \n",
    "    # Create a new column indicating whether GPS coordinates exist\n",
    "    result['lat_lon'] = ~result['Start GPS Co-ordinates'].isna() & ~result['End GPS Co-ordinates'].isna()\n",
    "\n",
    "    # Keep only the columns needed for your Rosetta stone\n",
    "    result = result[['road_id', 'full_road_name', 'Road Name', 'Corridor ID', 'Processed_Full_Road_Name', 'lat_lon']]\n",
    "    \n",
    "    # Save the Rosetta stone to a CSV file\n",
    "    result.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Save the rows that did not join to a separate CSV file\n",
    "    not_joined = shu[~shu['Corridor ID'].isin(result['Corridor ID'])]\n",
    "    not_joined.to_csv(\"not_joined.csv\", index=False)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute and do the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = join_corridors(\"shu_raw/local2.csv\", \"join_table.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note now you have \"join_table.csv\" this should be manually checked and edited, to confirm roads have joined correctly. Deleting duplicates manually is recommended before continuing. Note we created \"rosetta_stone.csv\" by manually filtering join_table to remove incorrect joins/duplicates and manually add not_joined."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_joined_data(df):\n",
    "    # Save the rows with missing GPS coordinates to a separate CSV\n",
    "    df_without_gps = df[df['Start GPS Co-ordinates'].isna() | df['End GPS Co-ordinates'].isna()]\n",
    "    df_without_gps.to_csv(\"without_gps.csv\", index=False)\n",
    "\n",
    "    # Keep only the rows with GPS coordinates for further processing\n",
    "    df = df.dropna(subset=['Start GPS Co-ordinates', 'End GPS Co-ordinates'])\n",
    "\n",
    "    # Discard duplicates based on 'Start GPS Co-ordinates'\n",
    "    df = df.drop_duplicates(subset=['Start GPS Co-ordinates'], keep='first')\n",
    "    \n",
    "    # Save rows that did not join to a separate CSV\n",
    "    not_joined = df[~df['Corridor ID'].isin(df['Corridor ID'])]\n",
    "    not_joined.to_csv(\"not_joined.csv\", index=False)\n",
    "\n",
    "    columns_to_keep = ['road_id', 'full_road_name', 'road_name_label', 'Road Name', 'Corridor ID', 'Land Use',\n",
    "                        'Traffic Volume', 'Street Category', 'Collective Risk Band', 'Personal Risk Band',\n",
    "                        'Posted Speed Limit', 'Free Flow Speed', 'IRR Band', 'Safe and Appropriate Speed',\n",
    "                        'Difference between posted speed limit and SaAS', 'Difference between operating and SaAS',\n",
    "                        'Proposed Permanent Speed Limit', 'Proposed Variable Speed Limit', 'Start GPS Co-ordinates',\n",
    "                        'End GPS Co-ordinates']\n",
    "    df = df[columns_to_keep]\n",
    "\n",
    "    df.to_csv(\"combined.csv\", index=False)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = process_joined_data(result_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for geo-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_linestring(geom):\n",
    "    return geom.geom_type == 'LineString'\n",
    "\n",
    "def safe_convert(coord):\n",
    "    try:\n",
    "        coord_list = ast.literal_eval(coord)\n",
    "        return Point(float(coord_list[1]), float(coord_list[0]))\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan\n",
    "    \n",
    "def closest_point(point, linestring):\n",
    "    closest_point = linestring.interpolate(linestring.project(point))\n",
    "    return closest_point\n",
    "\n",
    "def cut_linestring_at_points(linestring, point1, point2):\n",
    "    fraction1 = linestring.project(point1)\n",
    "    fraction2 = linestring.project(point2)\n",
    "\n",
    "    if fraction1 > fraction2:\n",
    "        fraction1, fraction2 = fraction2, fraction1\n",
    "\n",
    "    # Get the coordinates between the two projected points\n",
    "    coords = [coord for coord in linestring.coords if fraction1 <= linestring.project(Point(coord)) <= fraction2]\n",
    "\n",
    "    # Include the projected points in the final segment\n",
    "    segment = LineString([linestring.interpolate(fraction1), *coords, linestring.interpolate(fraction2)])\n",
    "\n",
    "    return segment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Geoprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anfe\\AppData\\Local\\Temp\\ipykernel_30264\\3280625780.py:29: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  merged_gdf.to_file(\"output/output.shp\")\n"
     ]
    }
   ],
   "source": [
    "road_network = gpd.read_file('explode-dissolve/roads.shp')\n",
    "road_network['road_id'] = road_network['road_id'].astype(str)\n",
    "\n",
    "df = pd.read_csv('combined.csv')\n",
    "\n",
    "df['StartPoint'] = df['Start GPS Co-ordinates'].apply(safe_convert)\n",
    "df['EndPoint'] = df['End GPS Co-ordinates'].apply(safe_convert)\n",
    "\n",
    "points_gdf = gpd.GeoDataFrame(df, geometry='StartPoint')W\n",
    "\n",
    "points_gdf['road_id'] = points_gdf['road_id'].astype('int64')\n",
    "road_network['road_id'] = road_network['road_id'].astype('int64')\n",
    "\n",
    "road_network.rename(columns={'geometry': 'geometry_road'}, inplace=True)\n",
    "merged_gdf = points_gdf.merge(road_network, how='left', on='road_id')\n",
    "\n",
    "# Filter out rows where 'geometry_road' is a MultiLineString\n",
    "merged_gdf = merged_gdf[merged_gdf['geometry_road'].apply(is_linestring)]\n",
    "\n",
    "merged_gdf['Start_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['StartPoint'], row['geometry_road']), axis=1)\n",
    "merged_gdf['End_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['EndPoint'], row['geometry_road']), axis=1)\n",
    "\n",
    "merged_gdf['Road_Segment'] = merged_gdf.apply(lambda row: cut_linestring_at_points(row['geometry_road'], row['Start_Closest_Point'], row['End_Closest_Point']), axis=1)\n",
    "\n",
    "merged_gdf.drop(columns=['StartPoint', 'Start_Closest_Point', 'geometry_road', 'End_Closest_Point', 'EndPoint'], inplace=True)\n",
    "\n",
    "merged_gdf.set_geometry('Road_Segment', inplace=True)\n",
    "\n",
    "merged_gdf.to_file(\"output/output.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
