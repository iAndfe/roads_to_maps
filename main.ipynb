{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing and Analyzing Road Networks\n",
    "\n",
    "This notebook is for processing road data by matching road names between two CSVs using fuzzy matching, then creating a linestring road segment from GPS co-ordinates. This is useful for when you get scammed to provide an overengineered solution when you do not have access to the original corridors geospatial dataset because of some legalease.\n",
    "\n",
    "It is recommended to create a virtual environment in this directory (.venv)\n",
    "\n",
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining preprocessing and fuzzy matching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_road_name(road_name):\n",
    "    if not isinstance(road_name, str):\n",
    "        return None\n",
    "    return road_name.lower()\n",
    "\n",
    "def fuzzy_match(row, choices, threshold):\n",
    "    if not isinstance(row, str):\n",
    "        return None\n",
    "    best_match, score = process.extractOne(row, choices)\n",
    "    if score > threshold:\n",
    "        return best_match\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to pre-process the CSV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_corridors(input_file, output_file, nojoin_output_file):\n",
    "    linz = pd.read_csv('linz_roads/nz-roads-addressing.csv')\n",
    "    corridors = pd.read_csv(input_file)\n",
    "\n",
    "    corridors['Road Name'] = corridors['Road Name'].astype(str)\n",
    "    corridors['Processed Road Name'] = corridors['Road Name'].apply(preprocess_road_name)\n",
    "    corridors_roads_list = corridors['Processed Road Name'].tolist()\n",
    "\n",
    "    linz['Processed_Full_Road_Name'] = linz['full_road_name'].apply(preprocess_road_name)\n",
    "    linz['Processed_Road_Name_Label'] = linz['road_name_label'].apply(preprocess_road_name)\n",
    "\n",
    "    threshold = 90\n",
    "    linz['Matched_Road_Full'] = linz['Processed_Full_Road_Name'].apply(lambda x: fuzzy_match(x, corridors_roads_list, threshold))\n",
    "    linz['Matched_Road_Label'] = linz['Processed_Road_Name_Label'].apply(lambda x: fuzzy_match(x, corridors_roads_list, threshold))\n",
    "\n",
    "    matched_roads = linz.dropna(subset=['Matched_Road_Full', 'Matched_Road_Label'], how='all')\n",
    "\n",
    "    result_full = matched_roads.merge(corridors, left_on='Matched_Road_Full', right_on='Processed Road Name', how='inner')\n",
    "    result_label = matched_roads.merge(corridors, left_on='Matched_Road_Label', right_on='Processed Road Name', how='inner')\n",
    "\n",
    "    result = pd.concat([result_full, result_label], ignore_index=True)\n",
    "    \n",
    "    # Create a new column indicating whether GPS coordinates exist\n",
    "    result['lat_lon'] = ~result['Start GPS Co-ordinates'].isna() & ~result['End GPS Co-ordinates'].isna()\n",
    "\n",
    "    # Keep only the columns needed for your Rosetta stone\n",
    "    result = result[['road_id', 'full_road_name', 'Road Name', 'Corridor ID', 'Processed_Full_Road_Name', 'lat_lon']]\n",
    "    \n",
    "    result = result.drop_duplicates(subset='Corridor ID', keep='first')\n",
    "\n",
    "    # Save the joined table to a CSV file\n",
    "    result.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Save the rows that did not join to a separate CSV file\n",
    "    not_joined = corridors[~corridors['Corridor ID'].isin(result['Corridor ID'])]\n",
    "    not_joined.to_csv(nojoin_output_file, index=False)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute and do the pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = join_corridors(input_file = \"input/sw.csv\",\n",
    "                           output_file = \"joined/join_table.csv\",\n",
    "                           nojoin_output_file = \"joined/not_joined.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note now you have \"join_table.csv\" this should be manually checked and edited, to confirm roads have joined correctly. Note we created \"rosetta_stone.csv\" by double checking any wrong matches, and manually adding the not_joined."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_joined_data(df, linz_file='linz_roads/nz-roads-addressing.csv', corridor_file='corridors.csv'):\n",
    "    # Load additional data\n",
    "    linz = pd.read_csv(linz_file)\n",
    "    corridors = pd.read_csv(corridor_file)\n",
    "\n",
    "    # Merge additional data\n",
    "    df = df.merge(linz, on='road_id', how='left', suffixes=('', '_linz'))\n",
    "    df = df.merge(corridors, on='Corridor ID', how='left', suffixes=('', '_corridors'))\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    df = df.loc[:,~df.columns.str.endswith('_linz')]\n",
    "    df = df.loc[:,~df.columns.str.endswith('_corridors')]\n",
    "\n",
    "    # Split the dataframe into two based on 'lat_lon'\n",
    "    df_with_gps = df[df['lat_lon'] == True]\n",
    "    df_without_gps = df[df['lat_lon'] == False]\n",
    "\n",
    "    # Remove duplicates based on 'Start GPS Co-ordinates'\n",
    "    df_with_gps = df_with_gps.drop_duplicates(subset=['Start GPS Co-ordinates'], keep='first')\n",
    "\n",
    "    # Specify the columns to keep\n",
    "    columns_to_keep = ['road_id', 'full_road_name', 'road_name_label', 'Road Name', 'Corridor ID', 'Land Use',\n",
    "                        'Traffic Volume', 'Street Category', 'Collective Risk Band', 'Personal Risk Band',\n",
    "                        'Posted Speed Limit', 'Free Flow Speed', 'IRR Band', 'Safe and Appropriate Speed',\n",
    "                        'Difference between posted speed limit and SaAS', 'Difference between operating and SaAS',\n",
    "                        'Proposed Permanent Speed Limit', 'Proposed Variable Speed Limit', 'Start GPS Co-ordinates',\n",
    "                        'End GPS Co-ordinates']\n",
    "\n",
    "    # Filter columns\n",
    "    df_with_gps = df_with_gps[columns_to_keep]\n",
    "    df_without_gps = df_without_gps[columns_to_keep]\n",
    "\n",
    "    # Save the rows with GPS coordinates to a separate CSV\n",
    "    df_with_gps.to_csv(\"joined/with_gps.csv\", index=False)\n",
    "\n",
    "    # Save the rows without GPS coordinates to a separate CSV\n",
    "    df_without_gps.to_csv(\"joined/without_gps.csv\", index=False)\n",
    "\n",
    "    return df_with_gps, df_without_gps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosetta_stone = pd.read_csv('joined/rosetta_stone.csv')\n",
    "processed_df = process_joined_data(rosetta_stone,\n",
    "                                   linz_file='linz_roads/nz-roads-addressing.csv',\n",
    "                                   corridor_file='input/sw.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for geo-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_linestring(geom):\n",
    "    return geom.geom_type == 'LineString'\n",
    "\n",
    "def safe_convert(coord):\n",
    "    try:\n",
    "        coord_list = ast.literal_eval(coord)\n",
    "        return Point(float(coord_list[1]), float(coord_list[0]))\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan\n",
    "    \n",
    "def closest_point(point, linestring):\n",
    "    closest_point = linestring.interpolate(linestring.project(point))\n",
    "    return closest_point\n",
    "\n",
    "def cut_linestring_at_points(linestring, point1, point2):\n",
    "    fraction1 = linestring.project(point1)\n",
    "    fraction2 = linestring.project(point2)\n",
    "\n",
    "    if fraction1 > fraction2:\n",
    "        fraction1, fraction2 = fraction2, fraction1\n",
    "\n",
    "    # Get the coordinates between the two projected points\n",
    "    coords = [coord for coord in linestring.coords if fraction1 <= linestring.project(Point(coord)) <= fraction2]\n",
    "\n",
    "    # Include the projected points in the final segment\n",
    "    segment = LineString([linestring.interpolate(fraction1), *coords, linestring.interpolate(fraction2)])\n",
    "\n",
    "    return segment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Geoprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2378522585.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[32], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    points_gdf = gpd.GeoDataFrame(df, geometry='StartPoint')W\u001b[0m\n\u001b[1;37m                                                            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "road_network = gpd.read_file('linz_roads/roads.shp')\n",
    "road_network['road_id'] = road_network['road_id'].astype(str)\n",
    "\n",
    "df = pd.read_csv('joined/with_gps.csv')\n",
    "\n",
    "df['StartPoint'] = df['Start GPS Co-ordinates'].apply(safe_convert)\n",
    "df['EndPoint'] = df['End GPS Co-ordinates'].apply(safe_convert)\n",
    "\n",
    "points_gdf = gpd.GeoDataFrame(df, geometry='StartPoint')\n",
    "\n",
    "points_gdf['road_id'] = points_gdf['road_id'].astype('int64')\n",
    "road_network['road_id'] = road_network['road_id'].astype('int64')\n",
    "\n",
    "road_network.rename(columns={'geometry': 'geometry_road'}, inplace=True)\n",
    "merged_gdf = points_gdf.merge(road_network, how='left', on='road_id')\n",
    "\n",
    "# Filter out rows where 'geometry_road' is a MultiLineString\n",
    "merged_gdf = merged_gdf[merged_gdf['geometry_road'].apply(is_linestring)]\n",
    "\n",
    "merged_gdf['Start_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['StartPoint'], row['geometry_road']), axis=1)\n",
    "merged_gdf['End_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['EndPoint'], row['geometry_road']), axis=1)\n",
    "\n",
    "merged_gdf['Road_Segment'] = merged_gdf.apply(lambda row: cut_linestring_at_points(row['geometry_road'], row['Start_Closest_Point'], row['End_Closest_Point']), axis=1)\n",
    "\n",
    "merged_gdf.drop(columns=['StartPoint', 'Start_Closest_Point', 'geometry_road', 'End_Closest_Point', 'EndPoint'], inplace=True)\n",
    "\n",
    "merged_gdf.set_geometry('Road_Segment', inplace=True)\n",
    "\n",
    "merged_gdf.to_file(\"output/output.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
