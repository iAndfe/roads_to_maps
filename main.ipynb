{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Roads to Maps\n",
    "\n",
    "This notebook is for processing road data by matching road names between two CSVs using fuzzy matching, then creating a linestring road segment from GPS co-ordinates, or joining directly when the relationship is one to one. This is useful for when you get scammed to provide an overengineered solution when you do not have access to the original corridors geospatial data because of some legalease.\n",
    "\n",
    "It is recommended to create a virtual environment in this directory (.venv)\n",
    "\n",
    "### Importing necessary libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from fuzzywuzzy import fuzz, process\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining preprocessing of road name and fuzzy matching functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_road_name(road_name):\n",
    "    if not isinstance(road_name, str):\n",
    "        return None\n",
    "    return road_name.lower()\n",
    "\n",
    "def fuzzy_match(row, choices, threshold):\n",
    "    if not isinstance(row, str):\n",
    "        return None\n",
    "    best_match, score = process.extractOne(row, choices)\n",
    "    if score > threshold:\n",
    "        return best_match\n",
    "    return None"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the function to join the CSV data (custom corridors and linz roads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_corridors(input_file, output_file, nojoin_output_file):\n",
    "    linz = pd.read_csv('linz_roads/nz-roads-addressing.csv')\n",
    "    corridors = pd.read_csv(input_file)\n",
    "\n",
    "    corridors['Road Name'] = corridors['Road Name'].astype(str)\n",
    "    corridors['Processed Road Name'] = corridors['Road Name'].apply(preprocess_road_name)\n",
    "    corridors_roads_list = corridors['Processed Road Name'].tolist()\n",
    "\n",
    "    linz['Processed_Full_Road_Name'] = linz['full_road_name'].apply(preprocess_road_name)\n",
    "    linz['Processed_Road_Name_Label'] = linz['road_name_label'].apply(preprocess_road_name)\n",
    "\n",
    "    threshold = 90\n",
    "    linz['Matched_Road_Full'] = linz['Processed_Full_Road_Name'].apply(lambda x: fuzzy_match(x, corridors_roads_list, threshold))\n",
    "    linz['Matched_Road_Label'] = linz['Processed_Road_Name_Label'].apply(lambda x: fuzzy_match(x, corridors_roads_list, threshold))\n",
    "\n",
    "    matched_roads = linz.dropna(subset=['Matched_Road_Full', 'Matched_Road_Label'], how='all')\n",
    "\n",
    "    result_full = matched_roads.merge(corridors, left_on='Matched_Road_Full', right_on='Processed Road Name', how='inner')\n",
    "    result_label = matched_roads.merge(corridors, left_on='Matched_Road_Label', right_on='Processed Road Name', how='inner')\n",
    "\n",
    "    result = pd.concat([result_full, result_label], ignore_index=True)\n",
    "    \n",
    "    # Create a new column indicating whether GPS coordinates exist\n",
    "    result['lat_lon'] = ~result['Start GPS Co-ordinates'].isna() & ~result['End GPS Co-ordinates'].isna()\n",
    "\n",
    "    # Keep only the columns needed for your Rosetta stone\n",
    "    result = result[['road_id', 'full_road_name', 'Road Name', 'Corridor ID', 'Processed_Full_Road_Name', 'lat_lon']]\n",
    "    \n",
    "    result = result.drop_duplicates(subset='Corridor ID', keep='first')\n",
    "\n",
    "    # Save the joined table to a CSV file\n",
    "    result.to_csv(output_file, index=False)\n",
    "    \n",
    "    # Save the rows that did not join to a separate CSV file\n",
    "    not_joined = corridors[~corridors['Corridor ID'].isin(result['Corridor ID'])]\n",
    "    not_joined.to_csv(nojoin_output_file, index=False)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute and join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = join_corridors(input_file = \"input/sw.csv\",\n",
    "                           output_file = \"joined/join_table.csv\",\n",
    "                           nojoin_output_file = \"joined/not_joined.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note now you have \"join_table.csv\" this should be manually checked and edited, to confirm roads have joined correctly. Note we created \"rosetta_stone.csv\" by double checking any wrong matches, and manually adding the not_joined."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the processing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_joined_data(df, linz_file, corridor_file):\n",
    "    # Load additional data\n",
    "    linz = pd.read_csv(linz_file)\n",
    "    corridors = pd.read_csv(corridor_file)\n",
    "\n",
    "    # Merge additional data\n",
    "    df = df.merge(linz, on='road_id', how='left', suffixes=('', '_linz'))\n",
    "    df = df.merge(corridors, on='Corridor ID', how='left', suffixes=('', '_corridors'))\n",
    "\n",
    "    # Remove duplicate columns\n",
    "    df = df.loc[:,~df.columns.str.endswith('_linz')]\n",
    "    df = df.loc[:,~df.columns.str.endswith('_corridors')]\n",
    "\n",
    "    # Split the dataframe into two based on 'lat_lon'\n",
    "    df_with_gps = df[df['lat_lon'] == True]\n",
    "    df_without_gps = df[df['lat_lon'] == False]\n",
    "\n",
    "    # Remove duplicates based on 'Start GPS Co-ordinates'\n",
    "    df_with_gps = df_with_gps.drop_duplicates(subset=['Start GPS Co-ordinates'], keep='first')\n",
    "\n",
    "    # Specify the columns to keep\n",
    "    columns_to_keep = ['road_id', 'full_road_name', 'road_name_label', 'Road Name', 'Corridor ID', 'Land Use',\n",
    "                        'Traffic Volume', 'Street Category', 'Collective Risk Band', 'Personal Risk Band',\n",
    "                        'Posted Speed Limit', 'Free Flow Speed', 'IRR Band', 'Safe and Appropriate Speed',\n",
    "                        'Difference between posted speed limit and SaAS', 'Difference between operating and SaAS',\n",
    "                        'Proposed Permanent Speed Limit', 'Proposed Variable Speed Limit', 'Start GPS Co-ordinates',\n",
    "                        'End GPS Co-ordinates']\n",
    "\n",
    "    # Filter columns\n",
    "    df_with_gps = df_with_gps[columns_to_keep]\n",
    "    df_without_gps = df_without_gps[columns_to_keep]\n",
    "\n",
    "    # Save the rows with GPS coordinates to a separate CSV\n",
    "    df_with_gps.to_csv(\"joined/with_gps.csv\", index=False)\n",
    "\n",
    "    # Save the rows without GPS coordinates to a separate CSV\n",
    "    df_without_gps.to_csv(\"joined/without_gps.csv\", index=False)\n",
    "\n",
    "    return df_with_gps, df_without_gps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute processing steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rosetta_stone = pd.read_csv('joined/rosetta_stone.csv')\n",
    "processed_df = process_joined_data(rosetta_stone,\n",
    "                                   linz_file='linz_roads/nz-roads-addressing.csv',\n",
    "                                   corridor_file='input/sw.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions for geo-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_linestring(geom):\n",
    "    return geom.geom_type == 'LineString'\n",
    "\n",
    "def safe_convert(coord):\n",
    "    try:\n",
    "        coord_list = ast.literal_eval(coord)\n",
    "        return Point(float(coord_list[1]), float(coord_list[0]))\n",
    "    except (ValueError, SyntaxError):\n",
    "        return np.nan\n",
    "    \n",
    "def closest_point(point, linestring):\n",
    "    closest_point = linestring.interpolate(linestring.project(point))\n",
    "    return closest_point\n",
    "\n",
    "def cut_linestring_at_points(linestring, point1, point2):\n",
    "    fraction1 = linestring.project(point1)\n",
    "    fraction2 = linestring.project(point2)\n",
    "\n",
    "    if fraction1 > fraction2:\n",
    "        fraction1, fraction2 = fraction2, fraction1\n",
    "\n",
    "    # Get the coordinates between the two projected points\n",
    "    coords = [coord for coord in linestring.coords if fraction1 <= linestring.project(Point(coord)) <= fraction2]\n",
    "\n",
    "    # Include the projected points in the final segment\n",
    "    segment = LineString([linestring.interpolate(fraction1), *coords, linestring.interpolate(fraction2)])\n",
    "\n",
    "    return segment\n",
    "\n",
    "def process_without_gps_data(df, linz_shp='linz_roads/roads.shp'):\n",
    "    # Load linz shapefile\n",
    "    road_network = gpd.read_file(linz_shp)\n",
    "    road_network['road_id'] = road_network['road_id'].astype('int64')\n",
    "\n",
    "    df['road_id'] = df['road_id'].astype('int64')\n",
    "\n",
    "    # Merge the geospatial data with the dataframe\n",
    "    nogps_merged_df = df.merge(road_network, how='left', on='road_id')\n",
    "\n",
    "    # Convert the DataFrame to GeoDataFrame\n",
    "    nogps_merged_gdf = gpd.GeoDataFrame(nogps_merged_df, geometry='geometry')\n",
    "\n",
    "    return nogps_merged_gdf\n",
    "\n",
    "def combine_geodataframes(gdf1, gdf2):\n",
    "    # Make sure both GeoDataFrames have the same CRS (coordinate reference system) before combining\n",
    "    gdf1.set_crs(\"EPSG:4326\", inplace=True)\n",
    "    gdf2.set_crs(\"EPSG:4326\", inplace=True)\n",
    "\n",
    "    # Concatenate the GeoDataFrames\n",
    "    combined_gdf = pd.concat([gdf1, gdf2], ignore_index=True)\n",
    "    return combined_gdf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute Geoprocessing Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anfe\\AppData\\Local\\Temp\\ipykernel_30736\\4009289402.py:55: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  combined_gdf.to_file(\"output/output.shp\")\n"
     ]
    }
   ],
   "source": [
    "road_network = gpd.read_file('linz_roads/roads.shp')\n",
    "road_network['road_id'] = road_network['road_id'].astype(str)\n",
    "\n",
    "df = pd.read_csv('joined/with_gps.csv')\n",
    "\n",
    "df['StartPoint'] = df['Start GPS Co-ordinates'].apply(safe_convert)\n",
    "df['EndPoint'] = df['End GPS Co-ordinates'].apply(safe_convert)\n",
    "\n",
    "points_gdf = gpd.GeoDataFrame(df, geometry='StartPoint')\n",
    "\n",
    "points_gdf['road_id'] = points_gdf['road_id'].astype('int64')\n",
    "road_network['road_id'] = road_network['road_id'].astype('int64')\n",
    "\n",
    "road_network.rename(columns={'geometry': 'geometry_road'}, inplace=True)\n",
    "merged_gdf = points_gdf.merge(road_network, how='left', on='road_id')\n",
    "\n",
    "# Filter out rows where 'geometry_road' is a MultiLineString\n",
    "merged_gdf = merged_gdf[merged_gdf['geometry_road'].apply(is_linestring)]\n",
    "\n",
    "merged_gdf['Start_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['StartPoint'], row['geometry_road']), axis=1)\n",
    "merged_gdf['End_Closest_Point'] = merged_gdf.apply(lambda row: closest_point(row['EndPoint'], row['geometry_road']), axis=1)\n",
    "\n",
    "merged_gdf['Road_Segment'] = merged_gdf.apply(lambda row: cut_linestring_at_points(row['geometry_road'], row['Start_Closest_Point'], row['End_Closest_Point']), axis=1)\n",
    "\n",
    "# Process the GPS data\n",
    "merged_gdf.drop(columns=['StartPoint', 'Start_Closest_Point', 'geometry_road', 'End_Closest_Point', 'EndPoint'], inplace=True)\n",
    "\n",
    "# Rename the 'Road_Segment' to 'geometry' in merged_gdf\n",
    "merged_gdf.rename(columns={'Road_Segment': 'geometry'}, inplace=True)\n",
    "\n",
    "# Now, set this new 'geometry' column as the active geometry\n",
    "merged_gdf.set_geometry('geometry', inplace=True)\n",
    "\n",
    "# Load the data without GPS\n",
    "df_no_gps = pd.read_csv('joined/without_gps.csv')\n",
    "\n",
    "# Process the data without GPS\n",
    "gdf_no_gps = process_without_gps_data(df_no_gps)\n",
    "\n",
    "# Combine the GeoDataFrames\n",
    "combined_gdf = combine_geodataframes(merged_gdf, gdf_no_gps)\n",
    "\n",
    "# Specify the columns to keep\n",
    "columns_to_keep = ['road_id', 'full_road_name', 'road_name_label', 'Road Name', 'Corridor ID', 'Land Use',\n",
    "                    'Traffic Volume', 'Street Category', 'Collective Risk Band', 'Personal Risk Band',\n",
    "                    'Posted Speed Limit', 'Free Flow Speed', 'IRR Band', 'Safe and Appropriate Speed',\n",
    "                    'Difference between posted speed limit and SaAS', 'Difference between operating and SaAS',\n",
    "                    'Proposed Permanent Speed Limit', 'Proposed Variable Speed Limit', 'Start GPS Co-ordinates',\n",
    "                    'End GPS Co-ordinates', 'geometry']\n",
    "\n",
    "# Filter columns\n",
    "combined_gdf = combined_gdf[columns_to_keep]\n",
    "\n",
    "# Save the combined GeoDataFrame to file\n",
    "combined_gdf.to_file(\"output/output.shp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
